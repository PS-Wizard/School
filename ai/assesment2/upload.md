# Introduction:
Artifical Intelligence (AI) has been a highly trending topic, especially in the past few years, thanks to tools like Chat-GPT and Midjourney; and rightfully so. These AI tools have had a profound impact in the way we do things, especially in the educational sector. Tools like Chat-GPT have become a one-stop-shop for learning and understanding basically any topic. However, with this widespread adoption, comes some serious concerns regarding the use of AI. These concerns fall into 3 categories: **transparency and explanability**, **biasness and descrimination** and **copyright and privacy**.

AI works as black boxes, especially in the case of neural networks. While this may sound simple at first glance, it challenges a fundamental human trait. Humans have the ability to think through a problem, and explain their thought process every step of the way, AI lacks that. This simple inability to explain how it came to a certain conclusion makes it so much harder to justify those answers (Trausan-Matu, 2020, p. 6). This becomes a much greater concern when paired with the conern for accountability. Its not a matter ofintersubjectivity "if", but "when" an AI makes mistakes, this inability to explain how it came to a conclusion makes it harder to prevent in the future. Furthermore, this calls a need on developers and the creators of the AI to take accountability for the decisions that their AI made, which at present remains absent ([Ubers Self-Driving Car Fatality](https://www.bbc.com/news/technology-33347866), [ Amazon's AI Recruiting Tool ](https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/),[COMPAS Algorithm in U.S. Criminal Justice](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)). Furthermore, a point is to be made on tools like Midjourney. AI produces results based on the data it was trained upon, data collected from **everyone**. So, if AI is using the insights and data from multiple individuals, who actually is to be credited for the results it produces?. These concerns raise ethical questions about the use of AI as it continues to be more embedded in our daily lives. The following sections of this report will attempt to highlight more of these dilemmas and provide possible solutions.
>
# The problems with LLMs in Education
We have already established that AI has its own ethical dilemmas, but now lets explore some of the more broader challenges with the use of LLMs and AI in general, in the context of education. 
## The issue with LLMs for generating educational content.
Starting with the fundamentals, AI is inheritly pattern recognition in a large scale. It trains on a set of data, recognizing a pattern and leverages that pattern to generate further responses. This inheritly implies that all knowledge of an AI is based on the data it is trained upon. This fundamental fact touches on many problems. Xu mentions that LLMs can reflect biases present in the data is was trained upon (Xu et al., 2024, p. 15). This might cause the AI to introduce biasness such as:
- Cultural and Regional Bias: LLMs might inadvertently choose or favour a more dominant cultural narrative which can neglect the voices of the minority. For example, historical events might be presented more from a Western viewpoint.
- Gender and Racial Stereotypes: Due the the same reason that Xu mentions, (Xu et al., 2024, p. 15) LLMs may produce stereotypical answers in its response,like associating professions with specific genders or simply bias in any way or form; see: ([ Amazon's AI Recruiting Tool ](https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/), [COMPAS Algorithm in U.S. Criminal Justice](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)). 
- Socioeconomic Bias: Even in cases that the LLMs dont produce any response, they are still not inclusive for the people with lower Socioeconomic backgrounds. For instance, AI-driven learning tools like [Duolingo](https://www.duolingo.com/) needs a stable internet access and capable personal devices, which may not be available to many students (Geiger, 2018).
## The issue with Automating Teacher-Student Interactions
Reduced human involvement in any field especially one that is as complex as education.  is never good.Education isn't simply "teach stuff", it envolves multiple layers such as critical thinking, emotionall intelligence and creativity. Sure, even if AI has the potential to automate the teacher-student interaction, it cannot and perhaps should never be a replacement.
### Importance of Intersubjectivity
Intersubjectivity, which is the ability to understand each other's perspectives is fundamental to human learning (Bailey, 2003, p.11). This understanding is possibly what makes us human and its something that AI simply cannot replicate. 
### One-size-fits-all model:
Teachers are great because they can tailor to each individual student. Our brains have been tailored to recognizing patterns, and sure one could make the argument that AI is better at that than us, but what AI lacks is a nuanced and perhaps a more emotional understanding. Teachers are so great because they can tailor to each student's learning patterns and their emotional state, which again something AI cannot replicate. This flows nicely to our next point,
### Lack of Emotional Intelligence: 
Sure, AI might be able to imitate emotions but it will never be as "real". Teachers unlike AI can understand other cues like body language or tone of voice that can give insight on how or why a student is behaving a certain way. This insight allows a teacher to adjust their approach based on the student's state. This is what AI simply can't take into account for, atleast not yet.
### 


