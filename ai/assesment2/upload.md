# Introduction:
Artifical Intelligence (AI) has been a highly trending topic, especially in the past few years, thanks to tools like Chat-GPT and Midjourney; and rightfully so. These AI tools have had a profound impact in the way we do things, especially in the educational sector. Tools like Chat-GPT have become a one-stop-shop for learning and understanding basically any topic. However, with this widespread adoption, comes some serious concerns regarding the use of AI. These concerns fall into 3 categories: **transparency and explanability**, **biasness and descrimination** and **copyright and privacy**.

AI works as black boxes, especially in the case of neural networks. While this may sound simple at first glance, it challenges a fundamental human trait. Humans have the ability to think through a problem, and explain their thought process every step of the way, AI lacks that. This simple inability to explain how it came to a certain conclusion makes it so much harder to justify those answers (Trausan-Matu, 2020, p. 6). This becomes a much greater concern when paired with the conern for accountability. Its not a matter ofintersubjectivity "if", but "when" an AI makes mistakes, this inability to explain how it came to a conclusion makes it harder to prevent in the future. Furthermore, this calls a need on developers and the creators of the AI to take accountability for the decisions that their AI made, which at present remains absent ([Ubers Self-Driving Car Fatality](https://www.bbc.com/news/technology-33347866), [ Amazon's AI Recruiting Tool ](https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/),[COMPAS Algorithm in U.S. Criminal Justice](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)). Furthermore, a point is to be made on tools like Midjourney. AI produces results based on the data it was trained upon, data collected from **everyone**. So, if AI is using the insights and data from multiple individuals, who actually is to be credited for the results it produces?. These concerns raise ethical questions about the use of AI as it continues to be more embedded in our daily lives. The following sections of this report will attempt to highlight more of these dilemmas and provide possible solutions.
>
# The problems with LLMs in Education
We have already established that AI has its own ethical dilemmas, but now lets explore some of the more broader challenges with the use of LLMs and AI in general, in the context of education. 
## The issue with LLMs for generating educational content.
Starting with the fundamentals, AI is inheritly pattern recognition in a large scale. It trains on a set of data, recognizing a pattern and leverages that pattern to generate further responses. This inheritly implies that all knowledge of an AI is based on the data it is trained upon. This fundamental fact touches on many problems. Xu mentions that LLMs can reflect biases present in the data is was trained upon (Xu et al., 2024, p. 15). This might cause the AI to introduce biasness such as:
- Cultural and Regional Bias: LLMs might inadvertently choose or favour a more dominant cultural narrative which can neglect the voices of the minority. For example, historical events might be presented more from a Western viewpoint.
- Gender and Racial Stereotypes: Due the the same reason that Xu mentions, (Xu et al., 2024, p. 15) LLMs may produce stereotypical answers in its response,like associating professions with specific genders or simply bias in any way or form; see: ([ Amazon's AI Recruiting Tool ](https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/), [COMPAS Algorithm in U.S. Criminal Justice](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)). 
- Socioeconomic Bias: Even in cases that the LLMs dont produce any response, they are still not inclusive for the people with lower Socioeconomic backgrounds. For instance, AI-driven learning tools like [Duolingo](https://www.duolingo.com/) needs a stable internet access and capable personal devices, which may not be available to many students (Geiger, 2018).
- Outdated Information: AI models only know as much information as their training data contains. Although they process an unfathomable amount of data, over time it still fades out of relevancy. This can cause the models to generated outdated or no longer relevant responses.

## The issue with Automating Teacher-Student Interactions
Reduced human involvement in any field especially one that is as complex as education.  is never good.Education isn't simply "teach stuff", it envolves multiple layers such as critical thinking, emotionall intelligence and creativity. Sure, even if AI has the potential to automate the teacher-student interaction, it cannot and perhaps should never be a replacement.
### Importance of Intersubjectivity
Intersubjectivity, which is the ability to understand each other's perspectives is fundamental to human learning (Bailey, 2003, p.11). This understanding is possibly what makes us human and its something that AI simply cannot replicate. 
### One-size-fits-all model:
Teachers are great because they can tailor to each individual student. Our brains have been tailored to recognizing patterns, and sure one could make the argument that AI is better at that than us, but what AI lacks is a nuanced and perhaps a more emotional understanding. Teachers are so great because they can tailor to each student's learning patterns and their emotional state, which again something AI cannot replicate. This flows nicely to our next point,
### Lack of Emotional Intelligence: 
Sure, AI might be able to imitate emotions but it will never be as "real". Teachers unlike AI can understand other cues like body language or tone of voice that can give insight on how or why a student is behaving a certain way. This insight allows a teacher to adjust their approach based on the student's state. This is what AI simply can't take into account for, atleast not yet.

## The Issue with AI in Assesment and Grading
### Lack of emotional nuances and understanding of creative answers
Previously we have already established that AI cannot capture emotional nuances. This might cause it to misjudge creative or unconventinoal answers albeit correct, which already makes it bad for assessing grades. 
### Lack of explainability
But, there's another significant flaw: the lack of explanability and transparency. Because AI works as "black box", there is no one clear explaination as to why it arrived to a certain answer. This lack of explanability makes it a very poor entity to grade any assesment (Trausan-Matu, 2020, p. 6). Also, AI can inadvertently favor certain phrasing simply because it had appeared more frequently in "statistically good" training data, which will skew its grading data.
>
# Strategies For Improvement
Having established that AI has clear room to improve, now the question boils down to the how?. While issues like emotional intelligence is hard to tackle, many of the other challenges can be solved with a few strategies. The following is an attempt to create a framework to improve the drawbacks of AI as of now that we've discussed.

- Diverse and Inclusive Training Data:
    We've shown that AI is prone to stereotypes and biasness. However, these flaws can be improved dramatically by fixing the training data. AI extracts its knowledge based off its training data, every stereotypes, every bias it produces is because it was prevelant in the training data. Then to solve this, the creators ought to incorporate a diverse range of training data; data that is inclusive, data that is just and data that has been "treated" best it can.

- Human-AI Collaboration:
    AI evidently is not going to be a drop in replacement for most human endevaours, especially not education. The best use for it, at this day and age, is to reduce the boilerplate work. So, instead of trying to forcefully use it where its not fit, it should rather be seen and used as a tool that supports learning. This approach maintains the essential "human" element to learning.

- Regular Audits and Updates:
    The creators of the AI should continuously monitor and update their AI to address issues. These issues might range from big mishaps: [Gemini Tells User to Die](https://news.sky.com/story/googles-ai-chatbot-gemini-tells-user-to-please-die-and-you-are-a-waste-of-time-and-resources-13256734) to the simple need for regular updates that adhears to the ever changing societial norms. This ensures that AI remains fair and accurate

- Accountability:
    The underlying workings of AI should be informed to the genral user. Only when the users know how these tools work, will they understand why it produces a certain response. Furthermore, creators of these AI tools shouldn't portray it as a solution to everything. They should accept and advertise the fact that their AI might make mistakes, and when they do, there need to be serious reprocusions.

# Discussion:
