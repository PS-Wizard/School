Introduction:
Artificial Intelligence (AI) has been a highly trending topic, especially in the past few years, thanks to tools like Chat-GPT and Midjourney; and rightfully so. These AI tools have had a profound impact in the way we do things, especially in the educational sector. Tools like Chat-GPT have become a one-stop-shop for learning and understanding basically any topic. However, with this widespread adoption, comes some serious concerns regarding the use of AI. 

AI works as black boxes, especially in the case of neural networks. While this may sound trivial, it challenges a fundamental human trait. Humans have the ability to think through a problem, and explain their thought process every step of the way, AI lacks that. This simple inability to explain how it came to a certain conclusion makes it so much harder to justify those answers (Trausan-Matu, 2020, p. 6). It's not a matter of "if", but "when" an AI makes mistakes, this inability to explain how it came to a conclusion makes it harder to prevent in the future. These along with other concerns raise questions about the use of AI. The following sections of this report will attempt to highlight more of these dilemmas and provide possible solutions especially in the educational field.
The problems with LLMs in Education
The issue with LLMs for generating educational content.
Starting with the fundamentals, AI is inherently pattern recognition on a large scale. It trains on a set of data, recognizing a pattern and leverages that pattern to generate further responses. This inherently implies that all knowledge of an AI is based on the data it is trained upon. This fundamental fact touches on many problems. Xu mentions that LLMs can reflect biases present in the data it was trained upon (Xu et al., 2024, p. 15). This might cause the AI to introduce biases such as:
Cultural, Regional and Socioeconomic Bias
LLMs might inadvertently choose or favour a more dominant cultural narrative which can neglect the voices of the minority. For example, historical events might be presented more from a Western viewpoint. Furthermore, AI is simply not accessible for the lower socioeconomic backgrounds, for instance, AI-driven learning tools like Duolingo needs a stable internet access and capable personal devices, which may not be available to many students (Geiger, 2018).
Gender and Racial Stereotypes
Due the the same reason that Xu mentions, (Xu et al., 2024, p. 15) LLMs may produce stereotypical answers in its response,like associating professions with specific genders or simply bias in any way or form; see:  Amazon's AI Recruiting Tool , COMPAS Algorithm in U.S. Criminal Justice, Google Photos Labels Black Individuals as "Gorillas".
Outdated Information:
AI models only know as much information as their training data contains. Although they process an unfathomable amount of data, over time it still fades out of relevancy. This can cause the models to generate outdated or no longer relevant responses.
The issue with Automating Teacher-Student Interactions
Reduced human involvement in any field, especially one that is as complex as education.  is never good.Education isn't simply "teach stuff", it involves multiple layers such as critical thinking, emotional intelligence and creativity. Sure, even if AI has the potential to automate the teacher-student interaction, it cannot and perhaps should never be a replacement.
Importance of Intersubjectivity
Intersubjectivity, which is the ability to understand each other's perspectives, is fundamental to human learning (Bailey, 2003, p.11). This understanding is possibly what makes us human and it's something that AI simply cannot replicate.
One-size-fits-all model:
Teachers are great because they can tailor to each individual student. Our brains have been tailored to recognizing patterns, and sure one could make the argument that AI is better at that than us, but what AI lacks is a nuanced and perhaps a more emotional understanding. Teachers are so great because they can tailor to each student's learning patterns and their emotional state, which again something AI cannot replicate. This flows nicely to our next point,
Lack of Emotional Intelligence:
Sure, AI might be able to imitate emotions but it will never be as "real". Teachers unlike AI can understand other cues like body language or tone of voice that can give insight on how or why a student is behaving a certain way. This insight allows a teacher to adjust their approach based on the student's state. This is what I simply can't take into account, at least not yet.
The Issue with AI in Assessment and Grading
Lack of emotional nuances and understanding of creative answers
Previously we have already established that AI cannot capture emotional nuances. This might cause it to misjudge creative or unconventional answers albeit correct, which already makes it bad for assessing grades.
Lack of explainability
But, there's another significant flaw: the lack of explainability and transparency. Because AI works as "black box", there is no one clear explanation as to why it arrived at a certain answer. This lack of explainability makes it a very poor entity to grade any assessment (Trausan-Matu, 2020, p. 6). Also, AI can inadvertently favor certain phrasing simply because it has appeared more frequently in "statistically good" training data, which will skew its grading data.

Copyright and Privacy Concerns:
Privacy, especially in the academic field, is something taken very seriously. AI provides responses based on the data it was trained upon, data collected from multiple individuals. This raises a critical question, who is to be credited to the insights or any breakthroughs made with the help of AI. This concern alone raises questions about whether using AI in the academic field is even appropriate. 

Furthermore, is it responsible to use AI that is trained upon unethical data? Incidents like: Clearview AI's Data Scraping Scandal, Facebook AI's Unauthorized Facial Recognition, DeepMind's NHS Data Scandal, Apple Siri Conversations Recorded Without Consent raise important questions. Granted that these issues concern the creators behind the AI rather than the technology itself, they still remain very important questions.
Strategies For Improvement
Having established that AI has clear room to improve, now the question boils down to the how?. While issues like emotional intelligence are hard to tackle, many of the other challenges can be solved with a few strategies. Acknowledging already established regulations such as European Union Guidelines, the following points aim to build upon these strategies to expand those principles especially in the context of education.

Diverse and Inclusive Training Data: We've shown that AI is prone to stereotypes and biases. However, these flaws can be improved dramatically by fixing the training data. AI extracts its knowledge based on its training data, every stereotype, every bias it produces is because it was prevalent in the training data. Then to solve this, the creators ought to incorporate a diverse range of training data; data that is inclusive, data that is just and data that has been "treated" best it can.

In: AI evidently is not going to be a drop in replacement for most human endeavors, especially not education. The best use for it, at this day and age, is to reduce the boilerplate work. So, instead of trying to forcefully use it where its not fit, it should rather be seen and used as a tool that supports learning. This approach maintains the essential "human" element to learning.

Regular Audits and Updates: The creators of the AI should continuously monitor and update their AI to address issues. These issues might range from big mishaps: Gemini Tells User to Die to the simple need for regular updates that adheres to the ever changing societal norms. This ensures that AI remains fair and accurate

Accountability: The underlying workings of AI should be informed to the general user. Only when the users know how these tools work, will they understand why it produces a certain response. Furthermore, creators of these AI tools shouldn't portray it as a solution to everything. They should accept and advertise the fact that their AI might make mistakes, and when they do, there need to be serious repercussions.
Discussion:
To conclude, although AI is sure to play a significant role in our day to day lives for the foreseeable future, it is also equally important to acknowledge its flaws. As of now, AI is not a viable replacement in the educational sector. While it is great at handling repetitive, tedious tasks or even assisting with education, it falls short when it comes to actual "teaching" and education as a whole. Firstly, its "black box" nature makes it difficult to justify its responses, which in a field like education where challenging opinions promote progress, is nothing less of a "flaw". Furthermore, it's lack of emotional intelligence, empathy and adaptability that teachers have is something crucial when it comes to teaching. Also it goes without saying that AI's generating stereotypical statements doesn't help. Therefore, with all these fundamental drawbacks, recommending LLMs and AI in general as a replacement in education would be an "uneducated" statement.


