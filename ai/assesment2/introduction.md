## Introduction [250 - 300 words]
1. What are the perceived ethical and moral issues with AI?
    - Transparency and explanability: 
        - **explanability**:  AI’s work as black boxes, no one knows how it works . Especially in the case of neural networks and deep learning. This inability to explain makes it difficult to justify how some of the decisions were made, and raises concerns.(Trausan-Matu, 2020, p. 6). 
        - **Accountability**: Following the above, when AI does make mistakes, who should be held accountable? A clear need for developers and makers of the AI to come up front and accept the accountability is needed which currently lacks.
        - As AI systems become more autonomous, determining accountability for their actions becomes increasingly complex. If an AI makes a harmful decision, it can be difficult to pinpoint whether the responsibility lies with the developers, the users, or the AI itself. This raises ethical questions about how to assign blame and ensure accountability.

    - Bias And Descrimination: 
        - Ai can make decisions based on biasness present in the training data, which because ai’s work as black boxes, sometimes cannot be explained. Further more machine learning algorithms may classify or discriminate people based on statistical averages, which could lead to unfairness situations type shit. (Trausan-Matu, 2020, p. 3,p. 6)
        - Catch 22: AI systems trained on historical data may inherit biases present in that data, leading to unfair outcomes. However, addressing these biases often requires altering the data or the algorithms, which can reduce the system's overall performance or accuracy. This creates a dilemma where improving fairness may compromise the effectiveness of the AI.

    - Copyright infringement / Privacy issues?:
        - Possibly point on like say image genearting AI’s, who does the credit belong to?
        - AI can infringe on individual privacy through data collection and surveillance, leading to potential misuse of personal information

2. What are the general and common ethical principles, guidelines and regulations that can attenuate these ethical and moral issues with AI?
    - **European Union Guidelines**: The EU has proposed regulations emphasizing ethical AI, including principles such as respect for human autonomy, prevention of harm, fairness, and explicability (Trausan-Matu, 2020, p. 4)
    - **AI HLEG Principles**: The High-Level Expert Group on AI has identified key ethical principles and requirements for trustworthy AI, including transparency, accountability, and respect for privacy (Trausan-Matu, 2020, p. 4,p. 5)

3. What are some of the necessary features and characteristics of an ethical AI? (what makes an AI ethical)
    - **Fairness**:  Ensuring that AI systems do not discriminate against individuals or groups and that they promote equitable outcomes (Trausan-Matu, 2020, p. 4)
    - **Explainability**:  Developing AI systems that can provide understandable justifications for their decisions, which is crucial for user trust (Trausan-Matu, 2020, p. 3)
    - **Transparency**:  Providing clear information about how AI systems operate and make decisions, which fosters trust and accountability (Trausan-Matu, 2020, p. 7)
    - **Accountability**: Establishing mechanisms to hold developers and organizations responsible for the actions of their AI systems Trausan-Matu, 2020, p. 5)


4. How to adhere to the ethics of AI to build ethical AI? ( how can ethical AI be built and maintained)
    - **Incorporating Ethical Principles**:  Developers should integrate ethical considerations into the design and development process of AI systems, ensuring that fairness, transparency, and accountability are prioritized
    
    - **Continuous Monitoring and Evaluation**: Regularly assessing AI systems for bias and ethical compliance is essential to maintain their integrity and trustworthiness

    - **User Education**: Informing users about the capabilities and limitations of AI systems can help them make informed decisions and understand the ethical implications of their use

    - **Stakeholder Involvement**: Engaging diverse stakeholders, including ethicists, policymakers, and affected communities, in the development process can help identify and address ethical concerns

- Ai can make decisions based on biasness present in the training data, which because ai’s work as black boxes, sometimes cannot be explained. Further more machine learning algorithms may classify or discriminate people based on statistical averages, which could lead to unfairness situations type shit. (Trausan-Matu, 2020, p. 3,p. 6)
    - Catch 22: AI systems trained on historical data may inherit biases present in that data, leading to unfair outcomes. However, addressing these biases often requires altering the data or the algorithms, which can reduce the system's overall performance or accuracy. This creates a dilemma where improving fairness may compromise the effectiveness of the AI.

    - Copyright infringement / Privacy issues?:
    - Possibly point on like say image genearting AI’s, who does the credit belong to?
    - AI can infringe on individual privacy through data collection and surveillance, leading to potential misuse of personal information
---

# Introduction:
Artifical Intelligence (AI) has been a highly trending topic, especially in the past few years, thanks to tools like Chat-GPT and Midjourney; and rightfully so. These AI tools have had a profound impact in the way we do things, especially in the educational sector. Tools like Chat-GPT have become a one-stop-shop for learning and understanding basically any topic. However, with this widespread adoption, comes some serious concerns regarding the use of AI. These concerns fall into 3 categories: **transparency and explanability**, **biasness and descrimination** and **copyright and privacy**.

AI works as black boxes, especially in the case of neural networks. While this may sound simple at first glance, it challenges a fundamental human trait. Humans have the ability to think through a problem, and explain their thought process every step of the way, AI lacks that. This simple inability to explain how it came to a certain conclusion makes it so much harder to justify those answers (Trausan-Matu, 2020, p. 6). This becomes a much greater concern when paired with the conern for accountability. Its not a matter of "if", but "when" an AI makes mistakes, this inability to explain how it came to a conclusion makes it harder to prevent in the future. Furthermore, this calls a need on developers and the creators of the AI to take accountability for the decisions that their AI made, which at present remains absent ([Ubers Self-Driving Car Fatality](https://www.bbc.com/news/technology-33347866), [ Amazon's AI Recruiting Tool ](https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/),[COMPAS Algorithm in U.S. Criminal Justice](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)). Furthermore, a point is to be made on tools like Midjourney. AI produces results based on the data it was trained upon, data collected from **everyone**. So, if AI is using the insights and data from multiple individuals, who actually is to be credited for the results it produces?. These concerns raise ethical questions about the use of AI as it continues to be more embedded in our daily lives. The following sections of this report will attempt to highlight more of these dilemmas and provide possible solutions.

